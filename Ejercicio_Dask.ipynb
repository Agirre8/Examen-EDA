{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#El ejercicio final pero solo con una muestra de 10000 filas para qu no tarde un tiempo excesivo en ejecutar todo\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "from sklearn.tree import DecisionTreeRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar las primeras 10000 líneas del archivo\n",
    "\n",
    "df = pd.read_csv(\"Datos/covtype.data\", nrows=500000)\n",
    "df.to_csv(\"Datos/covtypeI.data\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = pd.read_csv(\"Datos/covtypeI.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_Wilderness_Area = [\"Wilderness_Area\" + str(i) for i in range(1, 5)]\n",
    "columnas_Soil_Type = [\"Soil_Type\" + str(i) for i in range(1, 41)]\n",
    "columnas_restantes = [\"Elevation\", \"Aspect\", \"Slope\", \"Horizontal_Distance_To_Hydrology\",\n",
    "\"Vertical_Distance_To_Hydrology\", \"Horizontal_Distance_To_Roadways\", \"Hillshade_9am\", \"Hillshade_Noon\",\n",
    "\"Hillshade_3pm\", \"Horizontal_Distance_To_Fire_Points\"]\n",
    "columna_ultima = [\"Cover_Type\"]\n",
    "columnas_final = columnas_restantes + columnas_Wilderness_Area + columnas_Soil_Type + columna_ultima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.columns = columnas_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EJERCICIO 1\n",
    "X = datos.drop('Cover_Type', axis=1)\n",
    "y = datos['Cover_Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor(random_state=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(random_state=100)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeRegressor(random_state=100)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Crear un modelo de árbol de decisión y ajustarlo a los datos:\n",
    "tree_model = DecisionTreeRegressor(random_state=100)\n",
    "tree_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtener las importancias de las variables:\n",
    "importances = pd.Series(tree_model.feature_importances_, index=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ordenar las importancias de las variables de mayor a menor:\n",
    "sorted_importances = importances.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcular la suma acumulada de las importancias y el porcentaje que representa cada variable:\n",
    "cumulative_importances = sorted_importances.cumsum()\n",
    "cumulative_importances_percent = 100*cumulative_importances/cumulative_importances[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Elevation', 'Horizontal_Distance_To_Fire_Points',\n",
      "       'Horizontal_Distance_To_Roadways', 'Horizontal_Distance_To_Hydrology',\n",
      "       'Vertical_Distance_To_Hydrology', 'Wilderness_Area3',\n",
      "       'Wilderness_Area1', 'Soil_Type32', 'Aspect', 'Hillshade_Noon',\n",
      "       'Hillshade_9am', 'Hillshade_3pm', 'Soil_Type39', 'Slope', 'Soil_Type33',\n",
      "       'Soil_Type38', 'Cover_Type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Seleccionar las variables que aglutinan hasta el 95% de la información requerida:\n",
    "selected_variables = cumulative_importances_percent[cumulative_importances_percent <= 95].index\n",
    "selected_variables = selected_variables.append(pd.Index([\"Cover_Type\"]))\n",
    "\n",
    "print(selected_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Elevation  Horizontal_Distance_To_Fire_Points  \\\n",
      "0            2590                                6225   \n",
      "1            2804                                6121   \n",
      "2            2785                                6211   \n",
      "3            2595                                6172   \n",
      "4            2579                                6031   \n",
      "...           ...                                 ...   \n",
      "499995       3235                                1366   \n",
      "499996       3234                                1376   \n",
      "499997       3233                                1387   \n",
      "499998       3235                                1398   \n",
      "499999       3237                                1410   \n",
      "\n",
      "        Horizontal_Distance_To_Roadways  Horizontal_Distance_To_Hydrology  \\\n",
      "0                                   390                               212   \n",
      "1                                  3180                               268   \n",
      "2                                  3090                               242   \n",
      "3                                   391                               153   \n",
      "4                                    67                               300   \n",
      "...                                 ...                               ...   \n",
      "499995                              914                               256   \n",
      "499996                              942                               268   \n",
      "499997                              969                               283   \n",
      "499998                              997                               300   \n",
      "499999                             1025                               319   \n",
      "\n",
      "        Vertical_Distance_To_Hydrology  Wilderness_Area3  Wilderness_Area1  \\\n",
      "0                                   -6                 0                 1   \n",
      "1                                   65                 0                 1   \n",
      "2                                  118                 0                 1   \n",
      "3                                   -1                 0                 1   \n",
      "4                                  -15                 0                 1   \n",
      "...                                ...               ...               ...   \n",
      "499995                              37                 0                 0   \n",
      "499996                              36                 0                 0   \n",
      "499997                              35                 0                 0   \n",
      "499998                              37                 0                 0   \n",
      "499999                              39                 0                 0   \n",
      "\n",
      "        Soil_Type32  Aspect  Hillshade_Noon  Hillshade_9am  Hillshade_3pm  \\\n",
      "0                 0      56             235            220            151   \n",
      "1                 0     139             238            234            135   \n",
      "2                 0     155             238            238            122   \n",
      "3                 0      45             234            220            150   \n",
      "4                 0     132             237            230            140   \n",
      "...             ...     ...             ...            ...            ...   \n",
      "499995            0     298             237            195            182   \n",
      "499996            0       0             233            215            156   \n",
      "499997            0       3             230            213            155   \n",
      "499998            1     346             231            209            160   \n",
      "499999            1      17             228            215            150   \n",
      "\n",
      "        Soil_Type39  Slope  Soil_Type33  Soil_Type38  Cover_Type  \n",
      "0                 0      2            0            0           5  \n",
      "1                 0      9            0            0           2  \n",
      "2                 0     18            0            0           2  \n",
      "3                 0      2            0            0           5  \n",
      "4                 0      6            0            0           2  \n",
      "...             ...    ...          ...          ...         ...  \n",
      "499995            0      9            0            0           2  \n",
      "499996            0      3            0            0           2  \n",
      "499997            0      5            0            0           1  \n",
      "499998            0      6            0            0           1  \n",
      "499999            0      6            0            0           1  \n",
      "\n",
      "[500000 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "datos_1 = datos[selected_variables]\n",
    "print(datos_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkIAAAGdCAYAAAD+JxxnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy89olMNAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAsE0lEQVR4nO3dfXSU9Z3//1fuZpIIk3BjElIIoFhiuAmSNGGqtmvJMmVTt1aOzVrWpoBa6OACcUHpuonr2d1wsFZREdt1azinKjd7FquA0DRIqCWABFO5a6oVGypOosXMAAsJJJ/fH/5yfRlASBSYMJ/n45zrnFzX5z3X9f5kwszrXFzXTIwxxggAAMBCsZFuAAAAIFIIQgAAwFoEIQAAYC2CEAAAsBZBCAAAWIsgBAAArEUQAgAA1iIIAQAAa8VHuoHerLOzU4cOHVLfvn0VExMT6XYAAEA3GGN05MgRZWZmKjb2/Od8CELncejQIQ0ZMiTSbQAAgM/h4MGDGjx48HlrCELn0bdvX0mf/iI9Hk+EuwEAAN0RCoU0ZMgQ5338fAhC59H132Eej4cgBADAFaY7l7VwsTQAALAWQQgAAFiLIAQAAKxFEAIAANYiCAEAAGsRhAAAgLUIQgAAwFoEIQAAYC2CEAAAsBZBCAAAWKtHQejhhx9WTExM2JKdne2MnzhxQn6/XwMGDFCfPn00ZcoUNTc3h+2jqalJxcXFSk5OVlpamubPn69Tp06F1WzevFnjx4+X2+3WiBEjVFVVdVYvS5cu1bBhw5SYmKjCwkLt2LEjbLw7vQAAALv1+IzQqFGj9OGHHzrLG2+84YzNmzdPr776qlavXq3a2lodOnRIt99+uzPe0dGh4uJitbe3a+vWrVq+fLmqqqpUXl7u1Bw4cEDFxcW65ZZb1NDQoLlz5+ruu+/Wxo0bnZqVK1eqrKxMFRUV2rVrl3Jzc+Xz+dTS0tLtXgAAAGR6oKKiwuTm5p5zrLW11SQkJJjVq1c72/bv328kmbq6OmOMMevXrzexsbEmEAg4NcuWLTMej8e0tbUZY4xZsGCBGTVqVNi+S0pKjM/nc9YLCgqM3+931js6OkxmZqaprKzsdi/dEQwGjSQTDAa7/RgAABBZPXn/7vEZoXfeeUeZmZm65pprNHXqVDU1NUmS6uvrdfLkSRUVFTm12dnZysrKUl1dnSSprq5OY8aMUXp6ulPj8/kUCoW0d+9ep+b0fXTVdO2jvb1d9fX1YTWxsbEqKipyarrTy7m0tbUpFAqFLQAAIHr1KAgVFhaqqqpKGzZs0LJly3TgwAHdfPPNOnLkiAKBgFwul1JTU8Mek56erkAgIEkKBAJhIahrvGvsfDWhUEjHjx/Xxx9/rI6OjnPWnL6PC/VyLpWVlUpJSXGWIUOGdO8Xcxk8VvIt5+f92deHrQMAgM8nvifFkydPdn4eO3asCgsLNXToUK1atUpJSUkXvbnLbeHChSorK3PWQ6FQrwpDAADg4vpCt8+npqbqy1/+st59911lZGSovb1dra2tYTXNzc3KyMiQJGVkZJx151bX+oVqPB6PkpKSNHDgQMXFxZ2z5vR9XKiXc3G73fJ4PGELAACIXl8oCB09elR/+tOfNGjQIOXl5SkhIUE1NTXOeGNjo5qamuT1eiVJXq9Xu3fvDru7q7q6Wh6PRzk5OU7N6fvoqunah8vlUl5eXlhNZ2enampqnJru9AIAANCj/xr753/+Z916660aOnSoDh06pIqKCsXFxenOO+9USkqKZsyYobKyMvXv318ej0f33XefvF6vJkyYIEmaNGmScnJydNddd2nx4sUKBAJ66KGH5Pf75Xa7JUkzZ87U008/rQULFmj69OnatGmTVq1apXXr1jl9lJWVqbS0VPn5+SooKNATTzyhY8eOadq0aZLUrV4AAAB6FIT+8pe/6M4779Rf//pXXX311brpppu0bds2XX311ZKkxx9/XLGxsZoyZYra2trk8/n0zDPPOI+Pi4vT2rVrNWvWLHm9Xl111VUqLS3VI4884tQMHz5c69at07x587RkyRINHjxYzz33nHw+n1NTUlKijz76SOXl5QoEAho3bpw2bNgQdgH1hXoBAACIMcaYSDfRW4VCIaWkpCgYDEb8eqHHSr6l+1eulfTpXWPrc6911s807MF1en9R8eVsDwCAXqMn79981xgAALAWQQgAAFiLIAQAAKxFEAIAANYiCAEAAGsRhAAAgLUIQgAAwFoEIQAAYC2CEAAAsBZBCAAAWIsgBAAArEUQAgAA1iIIAQAAaxGEAACAtQhCAADAWgQhAABgLYIQAACwFkEIAABYiyAEAACsRRACAADWIggBAABrEYQAAIC1CEIAAMBaBCEAAGAtghAAALAWQQgAAFiLIAQAAKxFEAIAANYiCAEAAGsRhAAAgLUIQgAAwFoEIQAAYC2CEAAAsBZBCAAAWIsgBAAArEUQAgAA1iIIAQAAaxGEAACAtQhCAADAWgQhAABgLYIQAACwFkEIAABYiyAEAACsRRACAADWIggBAABrEYQAAIC1CEIAAMBaBCEAAGAtghAAALAWQQgAAFiLIAQAAKxFEAIAANYiCAEAAGsRhAAAgLUIQgAAwFoEIQAAYC2CEAAAsBZBCAAAWIsgBAAArEUQAgAA1vpCQWjRokWKiYnR3LlznW0nTpyQ3+/XgAED1KdPH02ZMkXNzc1hj2tqalJxcbGSk5OVlpam+fPn69SpU2E1mzdv1vjx4+V2uzVixAhVVVWddfylS5dq2LBhSkxMVGFhoXbs2BE23p1eAACAvT53EHrzzTf1s5/9TGPHjg3bPm/ePL366qtavXq1amtrdejQId1+++3OeEdHh4qLi9Xe3q6tW7dq+fLlqqqqUnl5uVNz4MABFRcX65ZbblFDQ4Pmzp2ru+++Wxs3bnRqVq5cqbKyMlVUVGjXrl3Kzc2Vz+dTS0tLt3sBAACWM5/DkSNHzHXXXWeqq6vN17/+dTNnzhxjjDGtra0mISHBrF692qndv3+/kWTq6uqMMcasX7/exMbGmkAg4NQsW7bMeDwe09bWZowxZsGCBWbUqFFhxywpKTE+n89ZLygoMH6/31nv6OgwmZmZprKystu9XEgwGDSSTDAY7Fb9pfST7xY7P+8bmR22fqahD6y9HC0BANAr9eT9+3OdEfL7/SouLlZRUVHY9vr6ep08eTJse3Z2trKyslRXVydJqqur05gxY5Senu7U+Hw+hUIh7d2716k5c98+n8/ZR3t7u+rr68NqYmNjVVRU5NR0p5cztbW1KRQKhS0AACB6xff0AStWrNCuXbv05ptvnjUWCATkcrmUmpoatj09PV2BQMCpOT0EdY13jZ2vJhQK6fjx4/rkk0/U0dFxzpo//OEP3e7lTJWVlfq3f/u388weAABEkx6dETp48KDmzJmjF154QYmJiZeqp4hZuHChgsGgsxw8eDDSLQEAgEuoR0Govr5eLS0tGj9+vOLj4xUfH6/a2lo9+eSTio+PV3p6utrb29Xa2hr2uObmZmVkZEiSMjIyzrpzq2v9QjUej0dJSUkaOHCg4uLizllz+j4u1MuZ3G63PB5P2AIAAKJXj4LQxIkTtXv3bjU0NDhLfn6+pk6d6vyckJCgmpoa5zGNjY1qamqS1+uVJHm9Xu3evTvs7q7q6mp5PB7l5OQ4Nafvo6umax8ul0t5eXlhNZ2dnaqpqXFq8vLyLtgLAACwW4+uEerbt69Gjx4dtu2qq67SgAEDnO0zZsxQWVmZ+vfvL4/Ho/vuu09er1cTJkyQJE2aNEk5OTm66667tHjxYgUCAT300EPy+/1yu92SpJkzZ+rpp5/WggULNH36dG3atEmrVq3SunXrnOOWlZWptLRU+fn5Kigo0BNPPKFjx45p2rRpkqSUlJQL9gIAAOzW44ulL+Txxx9XbGyspkyZora2Nvl8Pj3zzDPOeFxcnNauXatZs2bJ6/XqqquuUmlpqR555BGnZvjw4Vq3bp3mzZunJUuWaPDgwXruuefk8/mcmpKSEn300UcqLy9XIBDQuHHjtGHDhrALqC/UCwAAsFuMMcZEuoneKhQKKSUlRcFgMOLXCz1W8i3dv3KtJGl/9vVan3uts36mYQ+u0/uLii9newAA9Bo9ef/mu8YAAIC1CEIAAMBaBCEAAGAtghAAALAWQQgAAFiLIAQAAKxFEAIAANYiCAEAAGsRhAAAgLUIQgAAwFoEIQAAYC2CEAAAsBZBCAAAWIsgBAAArEUQAgAA1iIIAQAAaxGEAACAtQhCAADAWgQhAABgLYIQAACwFkEIAABYiyAEAACsRRACAADWIggBAABrEYQAAIC1CEIAAMBaBCEAAGAtghAAALAWQQgAAFiLIAQAAKxFEAIAANYiCAEAAGsRhAAAgLUIQgAAwFoEIQAAYC2CEAAAsBZBCAAAWIsgBAAArEUQAgAA1iIIAQAAaxGEAACAtQhCAADAWgQhAABgLYIQAACwFkEIAABYiyAEAACsRRACAADWIggBAABrEYQAAIC1CEIAAMBaBCEAAGAtghAAALAWQQgAAFiLIAQAAKxFEAIAANYiCAEAAGsRhAAAgLUIQgAAwFoEIQAAYK0eBaFly5Zp7Nix8ng88ng88nq9eu2115zxEydOyO/3a8CAAerTp4+mTJmi5ubmsH00NTWpuLhYycnJSktL0/z583Xq1Kmwms2bN2v8+PFyu90aMWKEqqqqzupl6dKlGjZsmBITE1VYWKgdO3aEjXenFwAAYLceBaHBgwdr0aJFqq+v186dO/WNb3xD3/72t7V3715J0rx58/Tqq69q9erVqq2t1aFDh3T77bc7j+/o6FBxcbHa29u1detWLV++XFVVVSovL3dqDhw4oOLiYt1yyy1qaGjQ3Llzdffdd2vjxo1OzcqVK1VWVqaKigrt2rVLubm58vl8amlpcWou1AsAAIDMF9SvXz/z3HPPmdbWVpOQkGBWr17tjO3fv99IMnV1dcYYY9avX29iY2NNIBBwapYtW2Y8Ho9pa2szxhizYMECM2rUqLBjlJSUGJ/P56wXFBQYv9/vrHd0dJjMzExTWVlpjDHd6qU7gsGgkWSCwWC3H3Op/OS7xc7P+0Zmh62faegDay9HSwAA9Eo9ef/+3NcIdXR0aMWKFTp27Ji8Xq/q6+t18uRJFRUVOTXZ2dnKyspSXV2dJKmurk5jxoxRenq6U+Pz+RQKhZyzSnV1dWH76Krp2kd7e7vq6+vDamJjY1VUVOTUdKeXc2lra1MoFApbAABA9OpxENq9e7f69Okjt9utmTNnas2aNcrJyVEgEJDL5VJqampYfXp6ugKBgCQpEAiEhaCu8a6x89WEQiEdP35cH3/8sTo6Os5Zc/o+LtTLuVRWViolJcVZhgwZ0r1fCgAAuCL1OAiNHDlSDQ0N2r59u2bNmqXS0lLt27fvUvR22S1cuFDBYNBZDh48GOmWAADAJRTf0we4XC6NGDFCkpSXl6c333xTS5YsUUlJidrb29Xa2hp2Jqa5uVkZGRmSpIyMjLPu7uq6k+v0mjPv7mpubpbH41FSUpLi4uIUFxd3zprT93GhXs7F7XbL7Xb34LcBAACuZF/4c4Q6OzvV1tamvLw8JSQkqKamxhlrbGxUU1OTvF6vJMnr9Wr37t1hd3dVV1fL4/EoJyfHqTl9H101XftwuVzKy8sLq+ns7FRNTY1T051eAAAAenRGaOHChZo8ebKysrJ05MgRvfjii9q8ebM2btyolJQUzZgxQ2VlZerfv788Ho/uu+8+eb1eTZgwQZI0adIk5eTk6K677tLixYsVCAT00EMPye/3O2diZs6cqaeffloLFizQ9OnTtWnTJq1atUrr1q1z+igrK1Npaany8/NVUFCgJ554QseOHdO0adMkqVu9AAAA9CgItbS06Pvf/74+/PBDpaSkaOzYsdq4caP+9m//VpL0+OOPKzY2VlOmTFFbW5t8Pp+eeeYZ5/FxcXFau3atZs2aJa/Xq6uuukqlpaV65JFHnJrhw4dr3bp1mjdvnpYsWaLBgwfrueeek8/nc2pKSkr00Ucfqby8XIFAQOPGjdOGDRvCLqC+UC8AAAAxxhgT6SZ6q1AopJSUFAWDQXk8noj28ljJt3T/yrWSpP3Z12t97rXO+pmGPbhO7y8qvpztAQDQa/Tk/ZvvGgMAANYiCAEAAGsRhAAAgLUIQgAAwFoEIQAAYC2CEAAAsBZBCAAAWIsgBAAArEUQAgAA1iIIAQAAaxGEAACAtQhCAADAWgQhAABgLYIQAACwFkEIAABYiyAEAACsRRACAADWIggBAABrEYQAAIC1CEJXkJpN10a6BQAAogpBCAAAWIsgBAAArEUQAgAA1iIIAQAAaxGEAACAtQhCAADAWgQhAABgLYIQAACwFkEIAABYiyAEAACsRRACAADWIggBAABrEYQAAIC1CEIAAMBaBCEAAGAtghAAALAWQQgAAFiLIAQAAKxFEAIAANYiCAEAAGsRhAAAgLUIQgAAwFoEIQAAYC2CEAAAsBZBCAAAWIsgBAAArEUQAgAA1iIIAQAAaxGEAACAtQhCAADAWgQhAABgLYIQAACwFkEIAABYiyAEAACsRRACAADWIggBAABrEYQAAIC1CEIAAMBaBCEAAGCtHgWhyspKfeUrX1Hfvn2Vlpam2267TY2NjWE1J06ckN/v14ABA9SnTx9NmTJFzc3NYTVNTU0qLi5WcnKy0tLSNH/+fJ06dSqsZvPmzRo/frzcbrdGjBihqqqqs/pZunSphg0bpsTERBUWFmrHjh097gUAANirR0GotrZWfr9f27ZtU3V1tU6ePKlJkybp2LFjTs28efP06quvavXq1aqtrdWhQ4d0++23O+MdHR0qLi5We3u7tm7dquXLl6uqqkrl5eVOzYEDB1RcXKxbbrlFDQ0Nmjt3ru6++25t3LjRqVm5cqXKyspUUVGhXbt2KTc3Vz6fTy0tLd3uBQAAWM58AS0tLUaSqa2tNcYY09raahISEszq1audmv379xtJpq6uzhhjzPr1601sbKwJBAJOzbJly4zH4zFtbW3GGGMWLFhgRo0aFXaskpIS4/P5nPWCggLj9/ud9Y6ODpOZmWkqKyu73cuFBINBI8kEg8Fu1V9KP/lusflNzTXGGGP2jcw2P/lu8WfWDn1g7eVqCwCAXqcn799f6BqhYDAoSerfv78kqb6+XidPnlRRUZFTk52draysLNXV1UmS6urqNGbMGKWnpzs1Pp9PoVBIe/fudWpO30dXTdc+2tvbVV9fH1YTGxuroqIip6Y7vZypra1NoVAobAEAANHrcwehzs5OzZ07VzfeeKNGjx4tSQoEAnK5XEpNTQ2rTU9PVyAQcGpOD0Fd411j56sJhUI6fvy4Pv74Y3V0dJyz5vR9XKiXM1VWViolJcVZhgwZ0s3fBgAAuBJ97iDk9/u1Z88erVix4mL2E1ELFy5UMBh0loMHD0a6JQAAcAnFf54HzZ49W2vXrtWWLVs0ePBgZ3tGRoba29vV2toadiamublZGRkZTs2Zd3d13cl1es2Zd3c1NzfL4/EoKSlJcXFxiouLO2fN6fu4UC9ncrvdcrvdPfhNAACAK1mPzggZYzR79mytWbNGmzZt0vDhw8PG8/LylJCQoJqaGmdbY2Ojmpqa5PV6JUler1e7d+8Ou7ururpaHo9HOTk5Ts3p++iq6dqHy+VSXl5eWE1nZ6dqamqcmu70AgAA7NajM0J+v18vvviifvWrX6lv377OtTYpKSlKSkpSSkqKZsyYobKyMvXv318ej0f33XefvF6vJkyYIEmaNGmScnJydNddd2nx4sUKBAJ66KGH5Pf7nbMxM2fO1NNPP60FCxZo+vTp2rRpk1atWqV169Y5vZSVlam0tFT5+fkqKCjQE088oWPHjmnatGlOTxfqBQAAWK4nt6NJOufy/PPPOzXHjx83P/rRj0y/fv1McnKy+c53vmM+/PDDsP28//77ZvLkySYpKckMHDjQ3H///ebkyZNhNa+//roZN26ccblc5pprrgk7RpennnrKZGVlGZfLZQoKCsy2bdvCxrvTy/lw+zwAAFeenrx/xxhjTORiWO8WCoWUkpKiYDAoj8cT0V4eK/mWxv1wvyZ+40/an3291udeq/tXrj1n7bAH1+n9RcWXuUMAAHqHnrx/811jAADAWgQhAABgLYIQAACwFkEIAABYiyAEAACsRRACAADWIggBAABrEYQAAIC1CEIAAMBaBCEAAGAtghAAALAWQQgAAFiLIAQAAKxFEAIAANYiCAEAAGsRhAAAgLUIQgAAwFoEoSvA/uzrI90CAABRiSAEAACsRRACAADWIggBAABrEYQAAIC1CEIAAMBaBCEAAGAtghAAALAWQQgAAFiLIAQAAKxFEAIAANYiCAEAAGsRhAAAgLUIQgAAwFoEIQAAYC2CEAAAsBZBCAAAWIsgBAAArEUQAgAA1iIIRYn92ddHugUAAK44BCEAAGAtghAAALAWQQgAAFiLIAQAAKxFEAIAANYiCAEAAGsRhAAAgLUIQlGmZtO1kW4BAIArBkEIAABYiyAEAACsRRACAADWIggBAABrEYQAAIC1CEIAAMBaBCEAAGAtghAAALAWQQgAAFiLIAQAAKxFEAIAANYiCAEAAGsRhAAAgLUIQhbiG+oBAPgUQQgAAFirx0Foy5YtuvXWW5WZmamYmBi9/PLLYePGGJWXl2vQoEFKSkpSUVGR3nnnnbCaw4cPa+rUqfJ4PEpNTdWMGTN09OjRsJq3335bN998sxITEzVkyBAtXrz4rF5Wr16t7OxsJSYmasyYMVq/fn2PewEAAPbqcRA6duyYcnNztXTp0nOOL168WE8++aSeffZZbd++XVdddZV8Pp9OnDjh1EydOlV79+5VdXW11q5dqy1btujee+91xkOhkCZNmqShQ4eqvr5ejz76qB5++GH9/Oc/d2q2bt2qO++8UzNmzNBbb72l2267Tbfddpv27NnTo14AAIDFzBcgyaxZs8ZZ7+zsNBkZGebRRx91trW2thq3221eeuklY4wx+/btM5LMm2++6dS89tprJiYmxnzwwQfGGGOeeeYZ069fP9PW1ubUPPDAA2bkyJHO+ne/+11TXFwc1k9hYaH54Q9/2O1eLiQYDBpJJhgMdqv+Utk3Mtv85LvF5jc114Stn1ljjDG/qbnGDH1g7Xn317UfoLe60N8wAJxPT96/L+o1QgcOHFAgEFBRUZGzLSUlRYWFhaqrq5Mk1dXVKTU1Vfn5+U5NUVGRYmNjtX37dqfma1/7mlwul1Pj8/nU2NioTz75xKk5/ThdNV3H6U4vZ2pra1MoFApbAABA9LqoQSgQCEiS0tPTw7anp6c7Y4FAQGlpaWHj8fHx6t+/f1jNufZx+jE+q+b08Qv1cqbKykqlpKQ4y5AhQ7oxawAAcKXirrHTLFy4UMFg0FkOHjwY6ZYAAMAldFGDUEZGhiSpubk5bHtzc7MzlpGRoZaWlrDxU6dO6fDhw2E159rH6cf4rJrTxy/Uy5ncbrc8Hk/YEk32Z18f6RYAAOhVLmoQGj58uDIyMlRTU+NsC4VC2r59u7xeryTJ6/WqtbVV9fX1Ts2mTZvU2dmpwsJCp2bLli06efKkU1NdXa2RI0eqX79+Ts3px+mq6TpOd3oBAAB263EQOnr0qBoaGtTQ0CDp04uSGxoa1NTUpJiYGM2dO1f//u//rldeeUW7d+/W97//fWVmZuq2226TJF1//fX65je/qXvuuUc7duzQ7373O82ePVv/8A//oMzMTEnS9773PblcLs2YMUN79+7VypUrtWTJEpWVlTl9zJkzRxs2bNBjjz2mP/zhD3r44Ye1c+dOzZ49W5K61QsAALBbfE8fsHPnTt1yyy3Oelc4KS0tVVVVlRYsWKBjx47p3nvvVWtrq2666SZt2LBBiYmJzmNeeOEFzZ49WxMnTlRsbKymTJmiJ5980hlPSUnRr3/9a/n9fuXl5WngwIEqLy8P+6yhr371q3rxxRf10EMP6cc//rGuu+46vfzyyxo9erRT051eAACAvXochP7mb/5GxpjPHI+JidEjjzyiRx555DNr+vfvrxdffPG8xxk7dqx++9vfnrfmjjvu0B133PGFegEAAPbirjEAAGAtghAAALAWQQgAAFiLIAQAAKxFEAIAANYiCAEAAGsRhAAAgLUIQgAAwFoEIQAAYC2CEAAAsBZBCAAAWIsgBAAArEUQAgAA1iIIAQAAaxGEAACAtQhCAADAWgQhAABgLYIQAACwFkEIAABYiyAEAACsRRACAADWIggBuCINe3BdpFsAEAUIQgAAwFoEIQAAYC2CEAAAsBZBCAAAWIsghDD7s6+PdAsAAFw2BCEAAGAtghAAALAWQQgAAFiLIAQAAKxFEAIAANYiCAEAAGsRhAAAgLUIQgAAwFoEIQAAYC2CEAAAsBZBCAAAWIsgBAAArEUQAgAA1iIIAQAAaxGEAACAtQhCAADAWgQhAABgLYIQAACwFkEIAABYiyCEHtuffX2kWwAA4KIgCKFXG7N8zEWpAQDgXAhCiJjLGWB6XVh6OCXSHQAARBACHFdkWLpYNQBgKYIQ0AO9LixdLIQlAJYiCAHoHsISgChEELIFb2KXTdSeNQKAKEQQAhC1hj24LtItAOjlCEIALh7OPAK4whCEcEnwoYsAgCsBQQjA5cVZIwC9CEEoGvDGAnwhXOAO2IsgdIXh4k8gMi7W1730thrAdlYEoaVLl2rYsGFKTExUYWGhduzYEemWAKBXICzBdlEfhFauXKmysjJVVFRo165dys3Nlc/nU0tLS6RbAwAAERb1QeinP/2p7rnnHk2bNk05OTl69tlnlZycrF/84heRbq17uP4HQKRF6/fe9bZ+EBHxkW7gUmpvb1d9fb0WLlzobIuNjVVRUZHq6urOqm9ra1NbW5uzHgwGJUmhUOjSN/tZ2oyOdnToxMmTOnasU51t/+esO339/zWhUMipOavnM2o+a05dNedzsWo6jttbozYjUfOZzvk3fIlqRldsVJ+Rvevvo7fVXNa/j8rB0sK/XJ6ai9XPRTThxQna9r1tX7jGdl1/08aYCxebKPbBBx8YSWbr1q1h2+fPn28KCgrOqq+oqDCSWFhYWFhYWKJgOXjw4AWzQlSfEeqphQsXqqyszFnv7OzU4cOHNWDAAMXExFz2fkKhkIYMGaKDBw/K4/Fc9uNHio3ztnHOEvNm3tHPxjlLkZ+3MUZHjhxRZmbmBWujOggNHDhQcXFxam5uDtve3NysjIyMs+rdbrfcbnfYttTU1EvZYrd4PB6r/gF1sXHeNs5ZYt62sXHeNs5Ziuy8U1JSulUX1RdLu1wu5eXlqaamxtnW2dmpmpoaeb3eCHYGAAB6g6g+IyRJZWVlKi0tVX5+vgoKCvTEE0/o2LFjmjZtWqRbAwAAERb1QaikpEQfffSRysvLFQgENG7cOG3YsEHp6emRbu2C3G63Kioqzvrvumhn47xtnLPEvJl39LNxztKVNe8YY7pzbxkAAED0ieprhAAAAM6HIAQAAKxFEAIAANYiCAEAAGsRhHqppUuXatiwYUpMTFRhYaF27NgR6ZZ6ZMuWLbr11luVmZmpmJgYvfzyy2HjxhiVl5dr0KBBSkpKUlFRkd55552wmsOHD2vq1KnyeDxKTU3VjBkzdPTo0bCat99+WzfffLMSExM1ZMgQLV68+FJP7TNVVlbqK1/5ivr27au0tDTddtttamxsDKs5ceKE/H6/BgwYoD59+mjKlClnfeBnU1OTiouLlZycrLS0NM2fP1+nTp0Kq9m8ebPGjx8vt9utESNGqKqq6lJP7zMtW7ZMY8eOdT44zev16rXXXnPGo3HOZ1q0aJFiYmI0d+5cZ1s0zvvhhx9WTExM2JKdne2MR+Ocu3zwwQf6x3/8Rw0YMEBJSUkaM2aMdu7c6YxH42vasGHDznq+Y2Ji5Pf7JUXR830xvtMLF9eKFSuMy+Uyv/jFL8zevXvNPffcY1JTU01zc3OkW+u29evXm3/5l38x//u//2skmTVr1oSNL1q0yKSkpJiXX37Z/P73vzd///d/b4YPH26OHz/u1Hzzm980ubm5Ztu2bea3v/2tGTFihLnzzjud8WAwaNLT083UqVPNnj17zEsvvWSSkpLMz372s8s1zTA+n888//zzZs+ePaahocH83d/9ncnKyjJHjx51ambOnGmGDBliampqzM6dO82ECRPMV7/6VWf81KlTZvTo0aaoqMi89dZbZv369WbgwIFm4cKFTs17771nkpOTTVlZmdm3b5956qmnTFxcnNmwYcNlnW+XV155xaxbt8788Y9/NI2NjebHP/6xSUhIMHv27DHGROecT7djxw4zbNgwM3bsWDNnzhxnezTOu6KiwowaNcp8+OGHzvLRRx8549E4Z2OMOXz4sBk6dKj5wQ9+YLZv327ee+89s3HjRvPuu+86NdH4mtbS0hL2XFdXVxtJ5vXXXzfGRM/zTRDqhQoKCozf73fWOzo6TGZmpqmsrIxgV5/fmUGos7PTZGRkmEcffdTZ1traatxut3nppZeMMcbs27fPSDJvvvmmU/Paa6+ZmJgY88EHHxhjjHnmmWdMv379TFtbm1PzwAMPmJEjR17iGXVPS0uLkWRqa2uNMZ/OMSEhwaxevdqp2b9/v5Fk6urqjDGfBsjY2FgTCAScmmXLlhmPx+PMc8GCBWbUqFFhxyopKTE+n+9ST6nb+vXrZ5577rmon/ORI0fMddddZ6qrq83Xv/51JwhF67wrKipMbm7uOceidc7GfPq6ctNNN33muC2vaXPmzDHXXnut6ezsjKrnm/8a62Xa29tVX1+voqIiZ1tsbKyKiopUV1cXwc4ungMHDigQCITNMSUlRYWFhc4c6+rqlJqaqvz8fKemqKhIsbGx2r59u1Pzta99TS6Xy6nx+XxqbGzUJ598cplm89mCwaAkqX///pKk+vp6nTx5Mmze2dnZysrKCpv3mDFjwj7w0+fzKRQKae/evU7N6fvoqukNfx8dHR1asWKFjh07Jq/XG/Vz9vv9Ki4uPqu3aJ73O++8o8zMTF1zzTWaOnWqmpqaJEX3nF955RXl5+frjjvuUFpamm644Qb913/9lzNuw2tae3u7fvnLX2r69OmKiYmJquebINTLfPzxx+ro6Djrk6/T09MVCAQi1NXF1TWP880xEAgoLS0tbDw+Pl79+/cPqznXPk4/RqR0dnZq7ty5uvHGGzV69GinJ5fLddYX+Z457wvN6bNqQqGQjh8/fimmc0G7d+9Wnz595Ha7NXPmTK1Zs0Y5OTlRPecVK1Zo165dqqysPGssWuddWFioqqoqbdiwQcuWLdOBAwd0880368iRI1E7Z0l67733tGzZMl133XXauHGjZs2apX/6p3/S8uXLJdnxmvbyyy+rtbVVP/jBD5x+ouX5jvqv2AAiwe/3a8+ePXrjjTci3cplMXLkSDU0NCgYDOp//ud/VFpaqtra2ki3dckcPHhQc+bMUXV1tRITEyPdzmUzefJk5+exY8eqsLBQQ4cO1apVq5SUlBTBzi6tzs5O5efn6z//8z8lSTfccIP27NmjZ599VqWlpRHu7vL47//+b02ePFmZmZmRbuWi44xQLzNw4EDFxcWddeV9c3OzMjIyItTVxdU1j/PNMSMjQy0tLWHjp06d0uHDh8NqzrWP048RCbNnz9batWv1+uuva/Dgwc72jIwMtbe3q7W1Naz+zHlfaE6fVePxeCL2ZuRyuTRixAjl5eWpsrJSubm5WrJkSdTOub6+Xi0tLRo/frzi4+MVHx+v2tpaPfnkk4qPj1d6enpUzvtMqamp+vKXv6x33303ap9rSRo0aJBycnLCtl1//fXOfwtG+2van//8Z/3mN7/R3Xff7WyLpuebINTLuFwu5eXlqaamxtnW2dmpmpoaeb3eCHZ28QwfPlwZGRlhcwyFQtq+fbszR6/Xq9bWVtXX1zs1mzZtUmdnpwoLC52aLVu26OTJk05NdXW1Ro4cqX79+l2m2fw/xhjNnj1ba9as0aZNmzR8+PCw8by8PCUkJITNu7GxUU1NTWHz3r17d9gLZnV1tTwej/NC7PV6w/bRVdOb/j46OzvV1tYWtXOeOHGidu/erYaGBmfJz8/X1KlTnZ+jcd5nOnr0qP70pz9p0KBBUftcS9KNN9541kdh/PGPf9TQoUMlRe9rWpfnn39eaWlpKi4udrZF1fN92S7LRretWLHCuN1uU1VVZfbt22fuvfdek5qaGnblfW935MgR89Zbb5m33nrLSDI//elPzVtvvWX+/Oc/G2M+vdU0NTXV/OpXvzJvv/22+fa3v33OW01vuOEGs337dvPGG2+Y6667LuxW09bWVpOenm7uuusus2fPHrNixQqTnJwcsVtNZ82aZVJSUszmzZvDbjn9v//7P6dm5syZJisry2zatMns3LnTeL1e4/V6nfGu200nTZpkGhoazIYNG8zVV199zttN58+fb/bv32+WLl0a0duLH3zwQVNbW2sOHDhg3n77bfPggw+amJgY8+tf/9oYE51zPpfT7xozJjrnff/995vNmzebAwcOmN/97nemqKjIDBw40LS0tBhjonPOxnz6EQnx8fHmP/7jP8w777xjXnjhBZOcnGx++ctfOjXR+JpmzKd3LWdlZZkHHnjgrLFoeb4JQr3UU089ZbKysozL5TIFBQVm27ZtkW6pR15//XUj6ayltLTUGPPp7ab/+q//atLT043b7TYTJ040jY2NYfv461//au68807Tp08f4/F4zLRp08yRI0fCan7/+9+bm266ybjdbvOlL33JLFq06HJN8Sznmq8k8/zzzzs1x48fNz/60Y9Mv379THJysvnOd75jPvzww7D9vP/++2by5MkmKSnJDBw40Nx///3m5MmTYTWvv/66GTdunHG5XOaaa64JO8blNn36dDN06FDjcrnM1VdfbSZOnOiEIGOic87ncmYQisZ5l5SUmEGDBhmXy2W+9KUvmZKSkrDP0onGOXd59dVXzejRo43b7TbZ2dnm5z//edh4NL6mGWPMxo0bjaSz5mJM9DzfMcYYc/nOPwEAAPQeXCMEAACsRRACAADWIggBAABrEYQAAIC1CEIAAMBaBCEAAGAtghAAALAWQQgAAFiLIAQAAKxFEAIAANYiCAEAAGsRhAAAgLX+Pwwe+Gy30REwAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#EJERCICIO2\n",
    "\n",
    "# Generar histograma de todas las variables\n",
    "plt.hist(datos_1.values, bins=50)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smite\\AppData\\Local\\Temp\\ipykernel_11792\\3532958195.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  datos_1[cols_to_normalize] = (datos_1[cols_to_normalize] - datos_1[cols_to_normalize].min()) / (datos_1[cols_to_normalize].max() - datos_1[cols_to_normalize].min())\n",
      "C:\\Users\\smite\\AppData\\Local\\Temp\\ipykernel_11792\\3532958195.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  datos_1['Cover_Type'] -= 1\n"
     ]
    }
   ],
   "source": [
    "# Obtener las columnas que se van a normalizar\n",
    "cols_to_normalize = datos_1.columns[:-1]\n",
    "\n",
    "# Normalizar los valores de las columnas\n",
    "datos_1[cols_to_normalize] = (datos_1[cols_to_normalize] - datos_1[cols_to_normalize].min()) / (datos_1[cols_to_normalize].max() - datos_1[cols_to_normalize].min())\n",
    "\n",
    "# Restar 1 del valor de la columna 'Cover_Type'\n",
    "datos_1['Cover_Type'] -= 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_norm = datos_1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EJERCICIO3\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "# dividir en train y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(datos_norm.iloc[:, :-1], datos_norm.iloc[:, -1], test_size=0.2, random_state=100)\n",
    "\n",
    "# entrenar modelo de regresión logística\n",
    "model = LogisticRegression(max_iter=1000, random_state=100)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.72649\n",
      "F1-score: 0.7126720542877559\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.68      0.70     35290\n",
      "           1       0.75      0.83      0.79     50228\n",
      "           2       0.63      0.81      0.71      5613\n",
      "           3       0.71      0.24      0.36       593\n",
      "           4       0.00      0.00      0.00      1859\n",
      "           5       0.41      0.16      0.23      2975\n",
      "           6       0.77      0.55      0.65      3442\n",
      "\n",
      "    accuracy                           0.73    100000\n",
      "   macro avg       0.57      0.47      0.49    100000\n",
      "weighted avg       0.71      0.73      0.71    100000\n",
      "\n",
      "Confusion matrix:\n",
      " [[24120 10603     2     0     0     7   558]\n",
      " [ 8155 41459   444     0    20   146     4]\n",
      " [    0   587  4541    41     3   441     0]\n",
      " [    0     2   394   142     0    55     0]\n",
      " [    2  1795    31     0     0    31     0]\n",
      " [    0   649  1831    18     0   477     0]\n",
      " [ 1509    23     0     0     0     0  1910]]\n"
     ]
    }
   ],
   "source": [
    "# predecir en datos de test y calcular métricas de evaluación\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "report = classification_report(y_test, y_pred, zero_division=0)\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# imprimir resultados\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1-score:\", f1)\n",
    "print(\"Classification report:\\n\", report)\n",
    "print(\"Confusion matrix:\\n\", matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.72649\n",
      "F1-score: 0.7126720542877559\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.68      0.70     35290\n",
      "           1       0.75      0.83      0.79     50228\n",
      "           2       0.63      0.81      0.71      5613\n",
      "           3       0.71      0.24      0.36       593\n",
      "           4       0.00      0.00      0.00      1859\n",
      "           5       0.41      0.16      0.23      2975\n",
      "           6       0.77      0.55      0.65      3442\n",
      "\n",
      "    accuracy                           0.73    100000\n",
      "   macro avg       0.57      0.47      0.49    100000\n",
      "weighted avg       0.71      0.73      0.71    100000\n",
      "\n",
      "Confusion matrix:\n",
      " [[24120 10603     2     0     0     7   558]\n",
      " [ 8155 41459   444     0    20   146     4]\n",
      " [    0   587  4541    41     3   441     0]\n",
      " [    0     2   394   142     0    55     0]\n",
      " [    2  1795    31     0     0    31     0]\n",
      " [    0   649  1831    18     0   477     0]\n",
      " [ 1509    23     0     0     0     0  1910]]\n"
     ]
    }
   ],
   "source": [
    "# predecir en datos de test y calcular métricas de evaluación\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "report = classification_report(y_test, y_pred, zero_division=0)\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# imprimir resultados\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1-score:\", f1)\n",
    "print(\"Classification report:\\n\", report)\n",
    "print(\"Confusion matrix:\\n\", matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EJERCICIO 4\n",
    "from dask_ml.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Crear modelo Decision Tree Classifier\n",
    "dtc = DecisionTreeClassifier(random_state=100)\n",
    "\n",
    "# Definir rango de profundidades\n",
    "depths = range(2, 31)\n",
    "\n",
    "# Definir parámetros de GridSearchCV\n",
    "param_grid = {'max_depth': depths}\n",
    "\n",
    "# Realizar GridSearchCV con Dask\n",
    "grid_search = GridSearchCV(dtc, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtener los resultados de GridSearchCV\n",
    "results = grid_search.cv_results_\n",
    "\n",
    "# Obtener los valores de los parámetros y el score\n",
    "params = results['params']\n",
    "scores = results['mean_test_score']\n",
    "\n",
    "# Crear gráfica de curva de complejidad\n",
    "plt.plot(depths, scores, '-o')\n",
    "plt.xlabel('Profundidad')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "def plot_learning_curve(estimator, X, y, cv, train_sizes=np.linspace(.1, 1.0, 10)):\n",
    "    \n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=-1, train_sizes=train_sizes)\n",
    "    \n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(\"Curva de Aprendizaje\")\n",
    "    plt.xlabel(\"Número de Muestras\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.grid()\n",
    "    \n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1,\n",
    "                     color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o--', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "    \n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()\n",
    "    \n",
    "# Generamos la curva de aprendizaje para el modelo Decision Tree Classifier con profundidad óptima\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=100)\n",
    "dtc = DecisionTreeClassifier(max_depth=12, random_state=100)\n",
    "plot_learning_curve(dtc, X, y, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EJERCICIO5\n",
    "import dask\n",
    "from dask import delayed\n",
    "from dask.distributed import Client\n",
    "\n",
    "# Creamos el cliente Dask\n",
    "client = Client()\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "@delayed\n",
    "def train_rfc(X_train, y_train, random_state, oob_score):\n",
    "    rfc = RandomForestClassifier(random_state=random_state, oob_score=oob_score)\n",
    "    rfc.fit(X_train, y_train)\n",
    "    return rfc\n",
    "\n",
    "rfc = train_rfc(X_train, y_train, random_state=100, oob_score=True)\n",
    "\n",
    "# Evaluación del modelo\n",
    "@delayed\n",
    "def eval_rfc(rfc, X_test, y_test):\n",
    "    y_pred = rfc.predict(X_test)\n",
    "\n",
    "    rfc_accuracy = accuracy_score(y_test, y_pred)\n",
    "    rfc_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    rfc_report = classification_report(y_test, y_pred, zero_division=0)\n",
    "    rfc_cm = confusion_matrix(y_test, y_pred)\n",
    "    rfc_oob = rfc.oobscore\n",
    "    tree_depths = [estimator.tree.maxdepth for estimator in rfc.estimators_]\n",
    "    median_tree_depth = np.median(tree_depths)\n",
    "    \n",
    "    return rfc_accuracy, rfc_f1, rfc_report, rfc_cm, rfc_oob, median_tree_depth\n",
    "\n",
    "results = eval_rfc(rfc, X_test, y_test)\n",
    "\n",
    "# Definición de los rangos para cada hiperparámetro\n",
    "n_estimators_range = [200, 300, 400]\n",
    "max_depth_range = [20, 30, None]\n",
    "max_features_range = [\"auto\", \"log2\", None]\n",
    "\n",
    "# Definición de los parámetros a evaluar en GridSearchCV\n",
    "params_grid = {\n",
    "    \"n_estimators\": n_estimators_range,\n",
    "    \"max_depth\": max_depth_range,\n",
    "    \"max_features\": max_features_range\n",
    "}\n",
    "\n",
    "# Entrenamiento del modelo óptimo\n",
    "@delayed\n",
    "def train_rfc_opt(X_train, y_train, params_grid, random_state):\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "    rfc_opt = GridSearchCV(RandomForestClassifier(oob_score=True, random_state=random_state), params_grid, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "    rfc_opt.fit(X_train, y_train)\n",
    "    return rfc_opt\n",
    "\n",
    "rfc_opt = train_rfc_opt(X_train, y_train, params_grid, random_state=100)\n",
    "\n",
    "# Evaluación del modelo óptimo\n",
    "@delayed\n",
    "def eval_rfc_opt(rfc_opt, X_test, y_test):\n",
    "    y_pred = rfc_opt.predict(X_test)\n",
    "\n",
    "    rfc_opt_accuracy = accuracy_score(y_test, y_pred)\n",
    "    rfc_opt_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    rfc_opt_report = classification_report(y_test, y_pred, zero_division=0)\n",
    "    rfc_opt_cm = confusion_matrix(y_test, y_pred)\n",
    "    rfc_opt_oob = rfc_opt.best_estimator_.oob_score_\n",
    "    \n",
    "    return rfc_opt_accuracy, rfc_opt_f1, rfc_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "# Definición de la función para obtener la gráfica del Learning Curve\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None, n_jobs=None, train_sizes=np.linspace(0.1, 1.0, 10)):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "title = \"Learning Curves (Random Forest)\"\n",
    "plot_learning_curve(RandomForestClassifier(n_estimators=350, max_depth=22, max_features='auto', random_state=100), title, X_train, y_train, cv=5, n_jobs=-1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las librerías necesarias\n",
    "#import xgboost as xgb\n",
    "#from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "# Crear el modelo\n",
    "#xgb_clf = xgb.XGBClassifier(random_state=100)\n",
    "\n",
    "# Entrenar el modelo\n",
    "#xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "# Realizar las predicciones\n",
    "#y_pred = xgb_clf.predict(X_test)\n",
    "\n",
    "# Calcular las métricas de evaluación\n",
    "#xgb_accuracy = accuracy_score(y_test, y_pred)\n",
    "#xgb_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "#xgb_report = classification_report(y_test, y_pred, zero_division=0)\n",
    "#xgb_cm = confusion_matrix(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# # Rangos de los hiperparámetros\n",
    "# n_estimators_range = np.arange(100, 501, 100)\n",
    "# max_depth_range = np.arange(6, 21, 2)\n",
    "# learning_rate_range = [0.01, 0.1, 0.3, 0.5]\n",
    "\n",
    "# # Definición de los parámetros a evaluar en GridSearchCV\n",
    "# params_grid = {\n",
    "#     \"n_estimators\": n_estimators_range,\n",
    "#     \"max_depth\": max_depth_range,\n",
    "#     \"learning_rate\": learning_rate_range\n",
    "# }\n",
    "\n",
    "# # Creación del modelo con GridSearchCV y evaluación\n",
    "# cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=100)\n",
    "# xgb_opt = GridSearchCV(xgb.XGBClassifier(random_state=100), params_grid, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# xgb_opt.fit(X_train, y_train)\n",
    "\n",
    "# # Evaluación del modelo óptimo\n",
    "# y_pred = xgb_opt.predict(X_test)\n",
    "\n",
    "# xgb_opt_accuracy = accuracy_score(y_test, y_pred)\n",
    "# xgb_opt_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "# xgb_opt_report = classification_report(y_test, y_pred, zero_division=0)\n",
    "# xgb_opt_cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "from dask_ml.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, ComplementNB, BernoulliNB\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.model_selection import learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Paso 5: Entrenar modelos Bayesianos con scikit-learn y calcular métricas\n",
    "# GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "y_pred_gnb = gnb.predict(X_test)\n",
    "accuracy_gnb = accuracy_score(y_test, y_pred_gnb)\n",
    "f1_gnb = f1_score(y_test, y_pred_gnb, average='weighted')\n",
    "classification_gnb = classification_report(y_test, y_pred_gnb, zero_division=0)\n",
    "\n",
    "# MultinomialNB\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train, y_train)\n",
    "y_pred_mnb = mnb.predict(X_test)\n",
    "accuracy_mnb = accuracy_score(y_test, y_pred_mnb)\n",
    "f1_mnb = f1_score(y_test, y_pred_mnb, average='weighted')\n",
    "classification_mnb = classification_report(y_test, y_pred_mnb, zero_division=0)\n",
    "\n",
    "# ComplementNB\n",
    "cnb = ComplementNB()\n",
    "cnb.fit(X_train, y_train)\n",
    "y_pred_cnb = cnb.predict(X_test)\n",
    "accuracy_cnb = accuracy_score(y_test, y_pred_cnb)\n",
    "f1_cnb = f1_score(y_test, y_pred_cnb, average='weighted')\n",
    "classification_cnb = classification_report(y_test, y_pred_cnb, zero_division=0)\n",
    "\n",
    "# BernoulliNB\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train, y_train)\n",
    "y_pred_bnb = bnb.predict(X_test)\n",
    "accuracy_bnb = accuracy_score(y_test, y_pred_bnb)\n",
    "f1_bnb = f1_score(y_test, y_pred_bnb, average='weighted')\n",
    "classification_bnb = classification_report(y_test, y_pred_bnb, zero_division=0)\n",
    "\n",
    "# Paso 7: Gráfica de Learning Curve para GaussianNB\n",
    "train_sizes, train_scores, test_scores = learning_curve(GaussianNB(), X_train, y_train, random_state=100, cv=5, train_sizes=[1000, 2000, 3000, 4000, 5000])\n",
    "\n",
    "# Calcular las medias y desviaciones estándar de los puntajes de entrenamiento y prueba\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "# Graficar la curva de aprendizaje\n",
    "plt.figure()\n",
    "plt.title(\"Curva de Aprendizaje - GaussianNB\")\n",
    "plt.xlabel(\"Número de muestras de entrenamiento\")\n",
    "plt.ylabel(\"Precisión\")\n",
    "plt.grid()\n",
    "\n",
    "plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Entrenamiento\")\n",
    "plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Prueba\")\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, ComplementNB, BernoulliNB\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "models = [GaussianNB(), MultinomialNB(), ComplementNB(), BernoulliNB()]\n",
    "\n",
    "for model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    class_report = classification_report(y_test, y_pred, zero_division=0)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print(type(model).__name__)\n",
    "    print(\"Accuracy: {:.4f}\".format(acc))\n",
    "    print(\"F1-score: {:.4f}\".format(f1))\n",
    "    print(\"Classification Report:\\n\", class_report)\n",
    "    print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[39mreturn\u001b[39;00m acc, f1, clf_report\n\u001b[0;32m     18\u001b[0m \u001b[39m# Convertir datos a dask.array\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m X_train_dask \u001b[39m=\u001b[39m da\u001b[39m.\u001b[39mfrom_array(X_train\u001b[39m.\u001b[39mvalues, chunks\u001b[39m=\u001b[39mX_train\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mshape)\n\u001b[0;32m     20\u001b[0m y_train_dask \u001b[39m=\u001b[39m da\u001b[39m.\u001b[39mfrom_array(y_train\u001b[39m.\u001b[39mvalues, chunks\u001b[39m=\u001b[39my_train\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mshape)\n\u001b[0;32m     22\u001b[0m \u001b[39m# K-Nearest Neighbors con configuración por defecto\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "#EJERCICIO 8\n",
    "import dask.array as da\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "def train_knn_model(n_neighbors):\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors, n_jobs=-1)\n",
    "    knn.fit(X_train_dask, y_train_dask)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    clf_report = classification_report(y_test, y_pred, zero_division=0)\n",
    "    return acc, f1, clf_report\n",
    "\n",
    "# Convertir datos a dask.array\n",
    "X_train_dask = da.from_array(X_train.values, chunks=X_train.values.shape)\n",
    "y_train_dask = da.from_array(y_train.values, chunks=y_train.values.shape)\n",
    "\n",
    "# K-Nearest Neighbors con configuración por defecto\n",
    "acc_default, f1_default, clf_report_default = train_knn_model(5)\n",
    "\n",
    "# K-Nearest Neighbors con 1 vecino\n",
    "acc_1, f1_1, clf_report_1 = train_knn_model(1)\n",
    "\n",
    "# K-Nearest Neighbors con 100 vecinos\n",
    "acc_100, f1_100, clf_report_100 = train_knn_model(100)\n",
    "\n",
    "# Imprimir métricas\n",
    "print(\"K-Nearest Neighbors con configuración por defecto:\")\n",
    "print(f\"Accuracy: {acc_default}\")\n",
    "print(f\"F1-score (weighted): {f1_default}\")\n",
    "print(\"Classification report:\")\n",
    "print(clf_report_default)\n",
    "print(\"----------------------------------------------------\")\n",
    "print(\"K-Nearest Neighbors con 1 vecino:\")\n",
    "print(f\"Accuracy: {acc_1}\")\n",
    "print(f\"F1-score (weighted): {f1_1}\")\n",
    "print(\"Classification report:\")\n",
    "print(clf_report_1)\n",
    "print(\"----------------------------------------------------\")\n",
    "print(\"K-Nearest Neighbors con 100 vecinos:\")\n",
    "print(f\"Accuracy: {acc_100}\")\n",
    "print(f\"F1-score (weighted): {f1_100}\")\n",
    "print(\"Classification report:\")\n",
    "print(clf_report_100)\n",
    "\n",
    "plot_learning_curve_knn(KNeighborsClassifier(n_neighbors=5), X_train_dask, y_train_dask, 5, cv=5)\n",
    "plot_learning_curve_knn(KNeighborsClassifier(n_neighbors=1), X_train_dask, y_train_dask, 1, cv=5)\n",
    "plot_learning_curve_knn(KNeighborsClassifier(n_neighbors=100), X_train_dask, y_train_dask, 100, cv=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smite\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\distributed\\node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 64374 instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#EJERCICIO 9\n",
    "import dask_ml.model_selection as dcv\n",
    "from dask.distributed import Client\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "# Crear cliente Dask para el cálculo distribuido\n",
    "client = Client()\n",
    "\n",
    "# MLPClassifier con configuración por defecto\n",
    "model_mlp1 = MLPClassifier(random_state=100)\n",
    "\n",
    "# Entrenamiento y evaluación paralelizados utilizando Dask\n",
    "with client:\n",
    "    model_mlp1 = dcv.GridSearchCV(model_mlp1, param_grid={}, cv=5, scoring='f1_weighted')\n",
    "    model_mlp1.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar modelo\n",
    "y_pred = model_mlp1.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "clf_report = classification_report(y_test, y_pred, zero_division=0)\n",
    "\n",
    "print(\"MLPClassifier con configuración por defecto:\")\n",
    "print(f\"Accuracy: {acc}\")\n",
    "print(f\"F1-score (weighted): {f1}\")\n",
    "print(\"Classification report:\")\n",
    "print(clf_report)\n",
    "\n",
    "# MLPClassifier con hiperparámetros definidos\n",
    "model_mlp2 = MLPClassifier(random_state=100, hidden_layer_sizes=(100, 200, 100), max_iter=10000, alpha=1e-5, tol=1e-5)\n",
    "\n",
    "# Entrenamiento y evaluación paralelizados utilizando Dask\n",
    "with client:\n",
    "    model_mlp2 = dcv.GridSearchCV(model_mlp2, param_grid={}, cv=5, scoring='f1_weighted')\n",
    "    model_mlp2.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar modelo\n",
    "y_pred = model_mlp2.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "clf_report = classification_report(y_test, y_pred, zero_division=0)\n",
    "\n",
    "print(\"\\nMLPClassifier con hiperparámetros definidos:\")\n",
    "print(f\"Accuracy: {acc}\")\n",
    "print(f\"F1-score (weighted): {f1}\")\n",
    "print(\"Classification report:\")\n",
    "print(clf_report)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
